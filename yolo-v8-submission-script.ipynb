{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91249,"databundleVersionId":11218843,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":224916709,"sourceType":"kernelVersion"},{"sourceId":225054260,"sourceType":"kernelVersion"}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!tar xfvz /kaggle/input/ultralytics-for-offline-install/archive.tar.gz\n!pip install --no-index --find-links=./packages ultralytics\n!rm -rf ./packages","metadata":{"trusted":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2025-04-06T13:38:05.469859Z","iopub.execute_input":"2025-04-06T13:38:05.470079Z","iopub.status.idle":"2025-04-06T13:39:04.430457Z","shell.execute_reply.started":"2025-04-06T13:38:05.470057Z","shell.execute_reply":"2025-04-06T13:39:04.429241Z"}},"outputs":[{"name":"stdout","text":"./packages/\n./packages/networkx-3.4.2-py3-none-any.whl\n./packages/fsspec-2025.2.0-py3-none-any.whl\n./packages/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n./packages/jinja2-3.1.5-py3-none-any.whl\n./packages/pyparsing-3.2.1-py3-none-any.whl\n./packages/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/ultralytics_thop-2.0.14-py3-none-any.whl\n./packages/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n./packages/urllib3-2.3.0-py3-none-any.whl\n./packages/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n./packages/pytz-2025.1-py2.py3-none-any.whl\n./packages/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/cycler-0.12.1-py3-none-any.whl\n./packages/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl\n./packages/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl\n./packages/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl\n./packages/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\n./packages/ultralytics-8.3.80-py3-none-any.whl\n./packages/mpmath-1.3.0-py3-none-any.whl\n./packages/kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n./packages/typing_extensions-4.12.2-py3-none-any.whl\n./packages/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/certifi-2025.1.31-py3-none-any.whl\n./packages/opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/tzdata-2025.1-py2.py3-none-any.whl\n./packages/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl\n./packages/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n./packages/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl\n./packages/fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl\n./packages/tqdm-4.67.1-py3-none-any.whl\n./packages/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl\n./packages/py_cpuinfo-9.0.0-py3-none-any.whl\n./packages/psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl\n./packages/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl\n./packages/triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/sympy-1.13.1-py3-none-any.whl\n./packages/seaborn-0.13.2-py3-none-any.whl\n./packages/scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/idna-3.10-py3-none-any.whl\n./packages/packaging-24.2-py3-none-any.whl\n./packages/matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n./packages/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n./packages/requests-2.32.3-py3-none-any.whl\n./packages/six-1.17.0-py2.py3-none-any.whl\n./packages/pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl\n./packages/filelock-3.17.0-py3-none-any.whl\nLooking in links: ./packages\nProcessing ./packages/ultralytics-8.3.80-py3-none-any.whl\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nProcessing ./packages/ultralytics_thop-2.0.14-py3-none-any.whl (from ultralytics)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.80 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom ultralytics import YOLO\nimport threading\nimport time\nfrom contextlib import nullcontext\nfrom concurrent.futures import ThreadPoolExecutor\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n# Define paths\ndata_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\ntest_dir = os.path.join(data_path, \"test\")\nsubmission_path = \"/kaggle/working/submission.csv\"\n\n# Model path - adjust if your best model is saved in a different location\nmodel_path = \"/kaggle/input/epoch-model/epoch70.pt\"\n\n# Detection parameters\nCONFIDENCE_THRESHOLD = 0.4  # Lower threshold to catch more potential motors\nMAX_DETECTIONS_PER_TOMO = 3  # Keep track of top N detections per tomogram\nNMS_IOU_THRESHOLD = 0.2  # Non-maximum suppression threshold for 3D clustering\nCONCENTRATION = 1 # ONLY PROCESS 1/20 slices for fast submission\n\n# GPU profiling context manager\nclass GPUProfiler:\n    def __init__(self, name):\n        self.name = name\n        self.start_time = None\n        \n    def __enter__(self):\n        if torch.cuda.is_available():\n            torch.cuda.synchronize()\n        self.start_time = time.time()\n        return self\n        \n    def __exit__(self, *args):\n        if torch.cuda.is_available():\n            torch.cuda.synchronize()\n        elapsed = time.time() - self.start_time\n        print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n\n# Check GPU availability and set up optimizations\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nBATCH_SIZE = 8  # Default batch size, will be adjusted dynamically if GPU available\n\nif device.startswith('cuda'):\n    # Set CUDA optimization flags\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 on Ampere GPUs\n    torch.backends.cudnn.allow_tf32 = True\n    \n    # Print GPU info\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n    \n    # Get available GPU memory and set batch size accordingly\n    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n    BATCH_SIZE = max(8, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n    print(f\"Dynamic batch size set to {BATCH_SIZE} based on {free_mem:.2f}GB free memory\")\nelse:\n    print(\"GPU not available, using CPU\")\n    BATCH_SIZE = 4  # Reduce batch size for CPU\n\ndef normalize_slice(slice_data):\n    \"\"\"\n    Normalize slice data using 2nd and 98th percentiles for better contrast\n    \"\"\"\n    p2 = np.percentile(slice_data, 2)\n    p98 = np.percentile(slice_data, 98)\n    clipped_data = np.clip(slice_data, p2, p98)\n    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n    return np.uint8(normalized)\n\ndef preload_image_batch(file_paths):\n    \"\"\"Preload a batch of images to CPU memory\"\"\"\n    images = []\n    for path in file_paths:\n        img = cv2.imread(path)\n        if img is None:\n            # Try with PIL as fallback\n            img = np.array(Image.open(path))\n        images.append(img)\n    return images\n\ndef process_tomogram(tomo_id, model, index=0, total=1):\n    \"\"\"\n    Process a single tomogram and return the most confident motor detection\n    \"\"\"\n    print(f\"Processing tomogram {tomo_id} ({index}/{total})\")\n    \n    # Get all slice files for this tomogram\n    tomo_dir = os.path.join(test_dir, tomo_id)\n    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n    \n    # Apply CONCENTRATION to reduce the number of slices processed\n    # This will process approximately CONCENTRATION fraction of all slices\n    selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * CONCENTRATION))\n    selected_indices = np.round(selected_indices).astype(int)\n    slice_files = [slice_files[i] for i in selected_indices]\n    \n    print(f\"Processing {len(slice_files)} out of {len(os.listdir(tomo_dir))} slices based on CONCENTRATION={CONCENTRATION}\")\n    \n    # Create a list to store all detections\n    all_detections = []\n    \n    # Create CUDA streams for parallel processing if using GPU\n    if device.startswith('cuda'):\n        streams = [torch.cuda.Stream() for _ in range(min(4, BATCH_SIZE))]\n    else:\n        streams = [None]\n    \n    # Variables for preloading\n    next_batch_thread = None\n    next_batch_images = None\n    \n    # Process slices in batches\n    for batch_start in range(0, len(slice_files), BATCH_SIZE):\n        # Wait for previous preload thread if it exists\n        if next_batch_thread is not None:\n            next_batch_thread.join()\n            next_batch_images = None\n            \n        batch_end = min(batch_start + BATCH_SIZE, len(slice_files))\n        batch_files = slice_files[batch_start:batch_end]\n        \n        # Start preloading next batch\n        next_batch_start = batch_end\n        next_batch_end = min(next_batch_start + BATCH_SIZE, len(slice_files))\n        next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []\n        \n        if next_batch_files:\n            next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]\n            next_batch_thread = threading.Thread(target=preload_image_batch, args=(next_batch_paths,))\n            next_batch_thread.start()\n        else:\n            next_batch_thread = None\n        \n        # Split batch across streams for parallel processing\n        sub_batches = np.array_split(batch_files, len(streams))\n        sub_batch_results = []\n        \n        for i, sub_batch in enumerate(sub_batches):\n            if len(sub_batch) == 0:\n                continue\n                \n            stream = streams[i % len(streams)]\n            with torch.cuda.stream(stream) if stream and device.startswith('cuda') else nullcontext():\n                # Process sub-batch\n                sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]\n                sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]\n                \n                # Run inference with profiling\n                with GPUProfiler(f\"Inference batch {i+1}/{len(sub_batches)}\"):\n                    sub_results = model(sub_batch_paths, verbose=False)\n                \n                # Process each result in this sub-batch\n                for j, result in enumerate(sub_results):\n                    if len(result.boxes) > 0:\n                        boxes = result.boxes\n                        for box_idx, confidence in enumerate(boxes.conf):\n                            if confidence >= CONFIDENCE_THRESHOLD:\n                                # Get bounding box coordinates\n                                x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()\n                                \n                                # Calculate center coordinates\n                                x_center = (x1 + x2) / 2\n                                y_center = (y1 + y2) / 2\n                                \n                                # Store detection with 3D coordinates\n                                all_detections.append({\n                                    'z': round(sub_batch_slice_nums[j]),\n                                    'y': round(y_center),\n                                    'x': round(x_center),\n                                    'confidence': float(confidence)\n                                })\n        \n        # Synchronize streams\n        if device.startswith('cuda'):\n            torch.cuda.synchronize()\n    \n    # Clean up thread if still running\n    if next_batch_thread is not None:\n        next_batch_thread.join()\n    \n    # 3D Non-Maximum Suppression to merge nearby detections across slices\n    final_detections = perform_3d_nms(all_detections, NMS_IOU_THRESHOLD)\n    \n    # Sort detections by confidence (highest first)\n    final_detections.sort(key=lambda x: x['confidence'], reverse=True)\n    \n    # If there are no detections, return NA values\n    if not final_detections:\n        return {\n            'tomo_id': tomo_id,\n            'Motor axis 0': -1,\n            'Motor axis 1': -1,\n            'Motor axis 2': -1\n        }\n    \n    # Take the detection with highest confidence\n    best_detection = final_detections[0]\n    \n    # Return result with integer coordinates\n    return {\n        'tomo_id': tomo_id,\n        'Motor axis 0': round(best_detection['z']),\n        'Motor axis 1': round(best_detection['y']),\n        'Motor axis 2': round(best_detection['x'])\n    }\n\ndef perform_3d_nms(detections, iou_threshold):\n    \"\"\"\n    Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n    \"\"\"\n    if not detections:\n        return []\n    \n    # Sort by confidence (highest first)\n    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n    \n    # List to store final detections after NMS\n    final_detections = []\n    \n    # Define 3D distance function\n    def distance_3d(d1, d2):\n        return np.sqrt((d1['z'] - d2['z'])**2 + \n                       (d1['y'] - d2['y'])**2 + \n                       (d1['x'] - d2['x'])**2)\n    \n    # Maximum distance threshold (based on box size and slice gap)\n    box_size = 24  # Same as annotation box size\n    distance_threshold = box_size * iou_threshold\n    \n    # Process each detection\n    while detections:\n        # Take the detection with highest confidence\n        best_detection = detections.pop(0)\n        final_detections.append(best_detection)\n        \n        # Filter out detections that are too close to the best detection\n        detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n    \n    return final_detections\n\ndef debug_image_loading(tomo_id):\n    \"\"\"\n    Debug function to check image loading\n    \"\"\"\n    tomo_dir = os.path.join(test_dir, tomo_id)\n    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n    \n    if not slice_files:\n        print(f\"No image files found in {tomo_dir}\")\n        return\n        \n    print(f\"Found {len(slice_files)} image files in {tomo_dir}\")\n    sample_file = slice_files[len(slice_files)//2]  # Middle slice\n    img_path = os.path.join(tomo_dir, sample_file)\n    \n    # Try different loading methods\n    try:\n        # Method 1: PIL\n        img_pil = Image.open(img_path)\n        img_array_pil = np.array(img_pil)\n        print(f\"PIL Image shape: {img_array_pil.shape}, dtype: {img_array_pil.dtype}\")\n        \n        # Method 2: OpenCV\n        img_cv2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        print(f\"OpenCV Image shape: {img_cv2.shape}, dtype: {img_cv2.dtype}\")\n        \n        # Method 3: Convert to RGB\n        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n        print(f\"OpenCV RGB Image shape: {img_rgb.shape}, dtype: {img_rgb.dtype}\")\n        \n        print(\"Image loading successful!\")\n    except Exception as e:\n        print(f\"Error loading image {img_path}: {e}\")\n        \n    # Also test with YOLO's built-in loader\n    try:\n        test_model = YOLO(model_path)\n        test_results = test_model([img_path], verbose=False)\n        print(\"YOLO model successfully processed the test image\")\n    except Exception as e:\n        print(f\"Error with YOLO processing: {e}\")\n\ndef generate_submission():\n    \"\"\"\n    Main function to generate the submission file\n    \"\"\"\n    # Get list of test tomograms\n    test_tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n    total_tomos = len(test_tomos)\n    \n    print(f\"Found {total_tomos} tomograms in test directory\")\n    \n    # Debug image loading for the first tomogram\n    if test_tomos:\n        debug_image_loading(test_tomos[0])\n    \n    # Clear GPU cache before starting\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    # Initialize model once outside the processing loop\n    print(f\"Loading YOLO model from {model_path}\")\n    model = YOLO(model_path)\n    model.to(device)\n    \n    # Additional optimizations for inference\n    if device.startswith('cuda'):\n        # Fuse conv and bn layers for faster inference\n        model.fuse()\n        \n        # Enable model half precision (FP16) if on compatible GPU\n        if torch.cuda.get_device_capability(0)[0] >= 7:  # Volta or newer\n            model.model.half()\n            print(\"Using half precision (FP16) for inference\")\n    \n    # Process tomograms with parallelization\n    results = []\n    motors_found = 0\n    \n    # Using ThreadPoolExecutor with max_workers=1 since each worker uses the GPU already\n    # and we're parallelizing within each tomogram processing\n    with ThreadPoolExecutor(max_workers=1) as executor:\n        future_to_tomo = {}\n        \n        # Submit all tomograms for processing\n        for i, tomo_id in enumerate(test_tomos, 1):\n            future = executor.submit(process_tomogram, tomo_id, model, i, total_tomos)\n            future_to_tomo[future] = tomo_id\n        \n        # Process completed futures as they complete\n        for future in future_to_tomo:\n            tomo_id = future_to_tomo[future]\n            try:\n                # Clear CUDA cache between tomograms\n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n                    \n                result = future.result()\n                results.append(result)\n                \n                # Update motors found count\n                has_motor = not pd.isna(result['Motor axis 0'])\n                if has_motor:\n                    motors_found += 1\n                    print(f\"Motor found in {tomo_id} at position: \"\n                          f\"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n                else:\n                    print(f\"No motor detected in {tomo_id}\")\n                    \n                print(f\"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n            \n            except Exception as e:\n                print(f\"Error processing {tomo_id}: {e}\")\n                # Create a default entry for failed tomograms\n                results.append({\n                    'tomo_id': tomo_id,\n                    'Motor axis 0': -1,\n                    'Motor axis 1': -1,\n                    'Motor axis 2': -1\n                })\n    \n    # Create submission dataframe\n    submission_df = pd.DataFrame(results)\n    \n    # Ensure proper column order\n    submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n    \n    # Save the submission file\n    submission_df.to_csv(submission_path, index=False)\n    \n    print(f\"\\nSubmission complete!\")\n    print(f\"Motors detected: {motors_found}/{total_tomos} ({motors_found/total_tomos*100:.1f}%)\")\n    print(f\"Submission saved to: {submission_path}\")\n    \n    # Display first few rows of submission\n    print(\"\\nSubmission preview:\")\n    print(submission_df.head())\n    \n    return submission_df\n\n# Run the submission pipeline\nif __name__ == \"__main__\":\n    # Time entire process\n    start_time = time.time()\n    \n    # Generate submission\n    submission = generate_submission()\n    \n    # Print total execution time\n    elapsed = time.time() - start_time\n    print(f\"\\nTotal execution time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T13:40:52.597905Z","iopub.execute_input":"2025-04-06T13:40:52.598476Z","iopub.status.idle":"2025-04-06T13:44:07.103062Z","shell.execute_reply.started":"2025-04-06T13:40:52.598429Z","shell.execute_reply":"2025-04-06T13:44:07.102257Z"}},"outputs":[{"name":"stdout","text":"[PROFILE] Inference batch 4/4: 0.549s\nUsing GPU: Tesla T4 with 15.83 GB memory\nDynamic batch size set to 32 based on 15.76GB free memory\nFound 3 tomograms in test directory\nFound 500 image files in /kaggle/input/byu-locating-bacterial-flagellar-motors-2025/test/tomo_003acc\nPIL Image shape: (1912, 1847), dtype: uint8\nOpenCV Image shape: (1912, 1847), dtype: uint8\nOpenCV RGB Image shape: (1912, 1847, 3), dtype: uint8\nImage loading successful!\n[PROFILE] Inference batch 1/4: 0.963s\n[PROFILE] Inference batch 2/4: 1.004s\n[PROFILE] Inference batch 3/4: 0.925s\n[PROFILE] Inference batch 4/4: 0.685s\n[PROFILE] Inference batch 1/4: 0.986s\n[PROFILE] Inference batch 2/4: 1.112s\n[PROFILE] Inference batch 3/4: 0.676s\n[PROFILE] Inference batch 4/4: 0.828s\n[PROFILE] Inference batch 1/4: 0.718s\n[PROFILE] Inference batch 2/4: 0.609s\n[PROFILE] Inference batch 3/4: 0.555s\n[PROFILE] Inference batch 4/4: 0.549s\n[PROFILE] Inference batch 1/4: 0.578s\nYOLO model successfully processed the test image\nLoading YOLO model from /kaggle/input/epoch-model/epoch70.pt\n[PROFILE] Inference batch 2/4: 0.675s\n[PROFILE] Inference batch 3/4: 0.606s\nModel summary (fused): 112 layers, 43,607,379 parameters, 0 gradients, 164.8 GFLOPs\nUsing half precision (FP16) for inference\nProcessing tomogram tomo_003acc (1/3)\nProcessing 500 out of 500 slices based on CONCENTRATION=1\n[PROFILE] Inference batch 4/4: 0.737s\n[PROFILE] Inference batch 1/4: 0.891s\n[PROFILE] Inference batch 2/4: 0.757s\n[PROFILE] Inference batch 3/4: 0.576s\n[PROFILE] Inference batch 4/4: 0.570s\n[PROFILE] Inference batch 1/4: 0.734s\n[PROFILE] Inference batch 2/4: 0.919s\n[PROFILE] Inference batch 3/4: 0.753s\n[PROFILE] Inference batch 4/4: 0.842s\n[PROFILE] Inference batch 1/4: 1.022s\n[PROFILE] Inference batch 2/4: 0.774s\n[PROFILE] Inference batch 3/4: 0.649s\n[PROFILE] Inference batch 4/4: 0.690s\n[PROFILE] Inference batch 1/4: 0.896s\n[PROFILE] Inference batch 2/4: 0.995s\n[PROFILE] Inference batch 3/4: 0.827s\n[PROFILE] Inference batch 4/4: 0.661s\n[PROFILE] Inference batch 1/4: 13.235s\n[PROFILE] Inference batch 1/4: 0.724s\n[PROFILE] Inference batch 2/4: 1.665s\n[PROFILE] Inference batch 2/4: 1.366s\n[PROFILE] Inference batch 3/4: 1.342s\n[PROFILE] Inference batch 3/4: 1.292s\n[PROFILE] Inference batch 4/4: 0.562s\n[PROFILE] Inference batch 4/4: 1.369s\n[PROFILE] Inference batch 1/4: 0.865s\n[PROFILE] Inference batch 2/4: 0.849s\n[PROFILE] Inference batch 1/4: 1.639s\n[PROFILE] Inference batch 3/4: 0.779s\n[PROFILE] Inference batch 2/4: 1.292s\n[PROFILE] Inference batch 4/4: 1.244s\n[PROFILE] Inference batch 1/4: 1.713s\n[PROFILE] Inference batch 3/4: 1.721s\n[PROFILE] Inference batch 2/4: 0.720s\n[PROFILE] Inference batch 4/4: 1.467s\n[PROFILE] Inference batch 3/4: 0.805s\n[PROFILE] Inference batch 4/4: 1.630s\n[PROFILE] Inference batch 1/4: 1.693s\n[PROFILE] Inference batch 1/4: 0.659s\n[PROFILE] Inference batch 2/4: 1.419s\n[PROFILE] Inference batch 2/4: 0.816s\n[PROFILE] Inference batch 3/4: 1.285s\n[PROFILE] Inference batch 3/4: 1.236s\n[PROFILE] Inference batch 4/4: 1.266s\n[PROFILE] Inference batch 4/4: 1.273s\n[PROFILE] Inference batch 1/4: 1.466s\n[PROFILE] Inference batch 1/4: 1.632s\n[PROFILE] Inference batch 2/4: 0.360s\n[PROFILE] Inference batch 2/4: 1.309s\n[PROFILE] Inference batch 3/4: 0.823s\n[PROFILE] Inference batch 4/4: 0.333s\nProcessing tomogram tomo_00e047 (2/3)\nProcessing 300 out of 300 slices based on CONCENTRATION=1\n[PROFILE] Inference batch 3/4: 1.264s\n[PROFILE] Inference batch 1/4: 0.948s\n[PROFILE] Inference batch 2/4: 0.312s\n[PROFILE] Inference batch 4/4: 1.326s\n[PROFILE] Inference batch 3/4: 0.956s\n[PROFILE] Inference batch 4/4: 0.451s\n[PROFILE] Inference batch 1/4: 0.314s\n[PROFILE] Inference batch 1/4: 1.581s\n[PROFILE] Inference batch 2/4: 0.859s\n[PROFILE] Inference batch 3/4: 0.189s\n[PROFILE] Inference batch 4/4: 0.184s\n[PROFILE] Inference batch 2/4: 1.280s\n[PROFILE] Inference batch 1/4: 0.906s\n[PROFILE] Inference batch 2/4: 0.228s\n[PROFILE] Inference batch 3/4: 0.183s\n[PROFILE] Inference batch 3/4: 1.256s\n[PROFILE] Inference batch 4/4: 0.846s\n[PROFILE] Inference batch 1/4: 0.217s\n[PROFILE] Inference batch 2/4: 0.218s\n[PROFILE] Inference batch 4/4: 1.426s\n[PROFILE] Inference batch 3/4: 0.937s\n[PROFILE] Inference batch 4/4: 0.197s\n[PROFILE] Inference batch 1/4: 0.246s\n[PROFILE] Inference batch 2/4: 0.308s\n[PROFILE] Inference batch 1/4: 1.609s\n[PROFILE] Inference batch 3/4: 0.905s\n[PROFILE] Inference batch 4/4: 0.193s\n[PROFILE] Inference batch 1/4: 0.225s\n[PROFILE] Inference batch 2/4: 1.370s\n[PROFILE] Inference batch 2/4: 0.938s\n[PROFILE] Inference batch 3/4: 0.186s\n[PROFILE] Inference batch 4/4: 0.182s\n[PROFILE] Inference batch 3/4: 1.277s\n[PROFILE] Inference batch 1/4: 0.909s\n[PROFILE] Inference batch 2/4: 0.190s\n[PROFILE] Inference batch 3/4: 0.194s\n[PROFILE] Inference batch 4/4: 1.285s\n[PROFILE] Inference batch 4/4: 0.906s\n[PROFILE] Inference batch 1/4: 0.262s\n[PROFILE] Inference batch 2/4: 0.265s\n[PROFILE] Inference batch 3/4: 0.228s\n[PROFILE] Inference batch 1/4: 1.697s\n[PROFILE] Inference batch 4/4: 0.889s\n[PROFILE] Inference batch 1/4: 0.283s\n[PROFILE] Inference batch 2/4: 0.191s\n[PROFILE] Inference batch 2/4: 1.319s\n[PROFILE] Inference batch 3/4: 0.889s\n[PROFILE] Inference batch 4/4: 0.185s\n[PROFILE] Inference batch 3/4: 1.297s\n[PROFILE] Inference batch 1/4: 1.222s\n[PROFILE] Inference batch 2/4: 0.077s\n[PROFILE] Inference batch 3/4: 0.075s\n[PROFILE] Inference batch 4/4: 0.070s\nProcessing tomogram tomo_01a877 (3/3)\nProcessing 300 out of 300 slices based on CONCENTRATION=1\n[PROFILE] Inference batch 4/4: 1.328s\n[PROFILE] Inference batch 1/4: 0.993s\n[PROFILE] Inference batch 2/4: 0.226s\n[PROFILE] Inference batch 3/4: 0.214s\n[PROFILE] Inference batch 4/4: 0.355s\n[PROFILE] Inference batch 1/4: 1.689s\n[PROFILE] Inference batch 1/4: 0.900s\n[PROFILE] Inference batch 2/4: 0.252s\n[PROFILE] Inference batch 3/4: 0.305s\n[PROFILE] Inference batch 4/4: 0.215s\n[PROFILE] Inference batch 2/4: 1.666s\n[PROFILE] Inference batch 1/4: 0.876s\n[PROFILE] Inference batch 2/4: 0.181s\n[PROFILE] Inference batch 3/4: 0.176s\n[PROFILE] Inference batch 4/4: 0.187s\n[PROFILE] Inference batch 3/4: 1.412s\n[PROFILE] Inference batch 1/4: 0.864s\n[PROFILE] Inference batch 2/4: 0.180s\n[PROFILE] Inference batch 3/4: 0.173s\n[PROFILE] Inference batch 4/4: 1.284s\n[PROFILE] Inference batch 4/4: 0.885s\n[PROFILE] Inference batch 1/4: 0.305s\n[PROFILE] Inference batch 2/4: 0.278s\n[PROFILE] Inference batch 3/4: 0.195s\n[PROFILE] Inference batch 1/4: 1.607s\n[PROFILE] Inference batch 4/4: 0.872s\n[PROFILE] Inference batch 1/4: 0.187s\n[PROFILE] Inference batch 2/4: 0.266s\n[PROFILE] Inference batch 3/4: 0.930s\n[PROFILE] Inference batch 2/4: 1.447s\n[PROFILE] Inference batch 4/4: 0.192s\n[PROFILE] Inference batch 1/4: 0.233s\n[PROFILE] Inference batch 3/4: 1.296s\n[PROFILE] Inference batch 2/4: 0.929s\n[PROFILE] Inference batch 3/4: 0.182s\n[PROFILE] Inference batch 4/4: 0.172s\n[PROFILE] Inference batch 4/4: 1.408s\n[PROFILE] Inference batch 1/4: 1.003s\n[PROFILE] Inference batch 2/4: 0.180s\n[PROFILE] Inference batch 3/4: 0.233s\n[PROFILE] Inference batch 4/4: 0.175s\n[PROFILE] Inference batch 1/4: 0.241s\n[PROFILE] Inference batch 1/4: 1.704s\n[PROFILE] Inference batch 2/4: 0.872s\n[PROFILE] Inference batch 3/4: 0.176s\n[PROFILE] Inference batch 4/4: 0.176s\n[PROFILE] Inference batch 1/4: 0.066s\n[PROFILE] Inference batch 2/4: 0.066s\n[PROFILE] Inference batch 3/4: 0.066s\n[PROFILE] Inference batch 2/4: 1.297s\n[PROFILE] Inference batch 4/4: 0.761s\n[PROFILE] Inference batch 3/4: 1.268s\n[PROFILE] Inference batch 4/4: 1.276s\n[PROFILE] Inference batch 1/4: 1.278s\n[PROFILE] Inference batch 2/4: 1.258s\n[PROFILE] Inference batch 3/4: 1.282s\n[PROFILE] Inference batch 4/4: 1.257s\n[PROFILE] Inference batch 1/4: 1.281s\n[PROFILE] Inference batch 2/4: 1.258s\n[PROFILE] Inference batch 3/4: 1.266s\n[PROFILE] Inference batch 4/4: 1.279s\n[PROFILE] Inference batch 1/4: 1.289s\n[PROFILE] Inference batch 2/4: 1.292s\n[PROFILE] Inference batch 3/4: 1.296s\n[PROFILE] Inference batch 4/4: 1.284s\n[PROFILE] Inference batch 1/4: 1.299s\n[PROFILE] Inference batch 2/4: 1.349s\n[PROFILE] Inference batch 3/4: 1.270s\n[PROFILE] Inference batch 4/4: 1.270s\n[PROFILE] Inference batch 1/4: 1.291s\n[PROFILE] Inference batch 2/4: 1.287s\n[PROFILE] Inference batch 3/4: 1.289s\n[PROFILE] Inference batch 4/4: 1.292s\n[PROFILE] Inference batch 1/4: 6.985s\n[PROFILE] Inference batch 2/4: 0.815s\n[PROFILE] Inference batch 3/4: 0.808s\n[PROFILE] Inference batch 4/4: 0.810s\nProcessing tomogram tomo_00e047 (2/3)\nMotor found in tomo_003acc at position: z=-1, y=-1, x=-1\nCurrent detection rate: 1/1 (100.0%)\nProcessing 300 out of 300 slices based on CONCENTRATION=1\n[PROFILE] Inference batch 1/4: 0.981s\n[PROFILE] Inference batch 2/4: 0.966s\n[PROFILE] Inference batch 3/4: 0.956s\n[PROFILE] Inference batch 4/4: 0.957s\n[PROFILE] Inference batch 1/4: 0.984s\n[PROFILE] Inference batch 2/4: 0.958s\n[PROFILE] Inference batch 3/4: 0.962s\n[PROFILE] Inference batch 4/4: 0.964s\n[PROFILE] Inference batch 1/4: 0.995s\n[PROFILE] Inference batch 2/4: 0.970s\n[PROFILE] Inference batch 3/4: 0.974s\n[PROFILE] Inference batch 4/4: 0.979s\n[PROFILE] Inference batch 1/4: 0.977s\n[PROFILE] Inference batch 2/4: 0.981s\n[PROFILE] Inference batch 3/4: 0.987s\n[PROFILE] Inference batch 4/4: 0.980s\n[PROFILE] Inference batch 1/4: 0.983s\n[PROFILE] Inference batch 2/4: 0.986s\n[PROFILE] Inference batch 3/4: 0.991s\n[PROFILE] Inference batch 4/4: 0.993s\n[PROFILE] Inference batch 1/4: 1.015s\n[PROFILE] Inference batch 2/4: 1.009s\n[PROFILE] Inference batch 3/4: 1.001s\n[PROFILE] Inference batch 4/4: 0.994s\n[PROFILE] Inference batch 1/4: 1.049s\n[PROFILE] Inference batch 2/4: 1.002s\n[PROFILE] Inference batch 3/4: 1.008s\n[PROFILE] Inference batch 4/4: 1.016s\n[PROFILE] Inference batch 1/4: 1.006s\n[PROFILE] Inference batch 2/4: 0.992s\n[PROFILE] Inference batch 3/4: 1.010s\n[PROFILE] Inference batch 4/4: 1.024s\n[PROFILE] Inference batch 1/4: 1.025s\n[PROFILE] Inference batch 2/4: 1.016s\n[PROFILE] Inference batch 3/4: 1.013s\n[PROFILE] Inference batch 4/4: 1.014s\n[PROFILE] Inference batch 1/4: 4.937s\n[PROFILE] Inference batch 2/4: 0.385s\n[PROFILE] Inference batch 3/4: 0.376s\n[PROFILE] Inference batch 4/4: 0.385s\nProcessing tomogram tomo_01a877 (3/3)\nMotor found in tomo_00e047 at position: z=162, y=547, x=603\nCurrent detection rate: 2/2 (100.0%)\nProcessing 300 out of 300 slices based on CONCENTRATION=1\n[PROFILE] Inference batch 1/4: 1.078s\n[PROFILE] Inference batch 2/4: 0.985s\n[PROFILE] Inference batch 3/4: 0.986s\n[PROFILE] Inference batch 4/4: 1.003s\n[PROFILE] Inference batch 1/4: 1.102s\n[PROFILE] Inference batch 2/4: 0.972s\n[PROFILE] Inference batch 3/4: 0.973s\n[PROFILE] Inference batch 4/4: 0.970s\n[PROFILE] Inference batch 1/4: 0.981s\n[PROFILE] Inference batch 2/4: 0.972s\n[PROFILE] Inference batch 3/4: 0.971s\n[PROFILE] Inference batch 4/4: 0.976s\n[PROFILE] Inference batch 1/4: 0.977s\n[PROFILE] Inference batch 2/4: 0.967s\n[PROFILE] Inference batch 3/4: 0.962s\n[PROFILE] Inference batch 4/4: 0.967s\n[PROFILE] Inference batch 1/4: 0.977s\n[PROFILE] Inference batch 2/4: 0.963s\n[PROFILE] Inference batch 3/4: 0.967s\n[PROFILE] Inference batch 4/4: 0.967s\n[PROFILE] Inference batch 1/4: 0.985s\n[PROFILE] Inference batch 2/4: 0.956s\n[PROFILE] Inference batch 3/4: 0.955s\n[PROFILE] Inference batch 4/4: 0.959s\n[PROFILE] Inference batch 1/4: 0.971s\n[PROFILE] Inference batch 2/4: 0.962s\n[PROFILE] Inference batch 3/4: 0.975s\n[PROFILE] Inference batch 4/4: 0.952s\n[PROFILE] Inference batch 1/4: 1.010s\n[PROFILE] Inference batch 2/4: 0.949s\n[PROFILE] Inference batch 3/4: 0.950s\n[PROFILE] Inference batch 4/4: 0.955s\n[PROFILE] Inference batch 1/4: 0.959s\n[PROFILE] Inference batch 2/4: 0.953s\n[PROFILE] Inference batch 3/4: 0.947s\n[PROFILE] Inference batch 4/4: 0.964s\n[PROFILE] Inference batch 1/4: 0.361s\n[PROFILE] Inference batch 2/4: 0.361s\n[PROFILE] Inference batch 3/4: 0.357s\n[PROFILE] Inference batch 4/4: 0.360s\nMotor found in tomo_01a877 at position: z=143, y=638, x=286\nCurrent detection rate: 3/3 (100.0%)\n\nSubmission complete!\nMotors detected: 3/3 (100.0%)\nSubmission saved to: /kaggle/working/submission.csv\n\nSubmission preview:\n       tomo_id  Motor axis 0  Motor axis 1  Motor axis 2\n0  tomo_003acc            -1            -1            -1\n1  tomo_00e047           162           547           603\n2  tomo_01a877           143           638           286\n\nTotal execution time: 194.44 seconds (3.24 minutes)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}